#!/usr/bin/env python3
"""
Sentence-Aware Chunking Demo
Using spaCy for better sentence boundary detection

What this demo shows:
This script demonstrates advanced chunking using spaCy for sentence-aware text splitting. It compares basic character-based chunking with intelligent sentence-boundary chunking, showing how breaking at natural language boundaries improves semantic coherence.

What you'll see:

Basic character-based chunking (may break mid-sentence)
spaCy-powered sentence-aware chunking
Side-by-side comparison of chunk quality
Analysis of sentence boundary preservation
Benefits of natural language processing for chunking

"""

from langchain.text_splitter import SpacyTextSplitter
import spacy

print("‚úÇÔ∏è Sentence-Aware Chunking Demo")
print("=" * 50)

# Download spaCy model if not already present
try:
    nlp = spacy.load("en_core_web_sm")
    print("‚úÖ spaCy model loaded successfully")
except OSError:
    print("‚ö†Ô∏è  spaCy model not found. Using basic chunking instead.")
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    nlp = None

# Sample document with complex sentences
sample_document = """
TechCorp Security Policy and Remote Work Guidelines

Employees working remotely must follow strict security protocols to protect company data and systems. All remote work must be conducted using company-approved devices and software, including laptops, monitors, and security software. Personal devices, including smartphones and tablets, are strictly prohibited for accessing company systems or storing confidential information.

The company provides VPN access to all remote employees, which must be used whenever accessing internal systems or databases. VPN connections must be established before accessing any company resources, and employees must ensure their internet connection is secure and private. Public Wi-Fi networks, including those in coffee shops, airports, and hotels, are not permitted for company work due to security risks.

All confidential documents must be stored in approved cloud storage systems with proper encryption and access controls. Local storage of sensitive information on personal computers or external drives is strictly forbidden. Employees must use strong passwords and enable two-factor authentication for all company accounts and systems.

Regular security training sessions are mandatory for all remote workers, covering topics such as phishing prevention, password management, and data handling procedures. Employees must complete these training modules within 30 days of starting remote work and annually thereafter. Failure to complete security training may result in suspension of remote work privileges.

Incident reporting procedures require immediate notification of any security breaches, suspicious activities, or potential data exposures to the IT security team. Employees must report incidents within 2 hours of discovery using the designated security hotline or email system. Delayed reporting may result in disciplinary action and potential legal consequences.
"""

print("üìÑ Sample Document:")
print(f"Length: {len(sample_document)} characters")
print(f"Complex sentences with multiple clauses")
print()

# Test 1: Basic character-based chunking
print("üîß Test 1: Basic Character-Based Chunking")
print("-" * 50)

from langchain.text_splitter import RecursiveCharacterTextSplitter

basic_splitter = RecursiveCharacterTextSplitter(
    chunk_size=400,
    chunk_overlap=50,
    separators=["\n\n", "\n", " ", ""]
)

basic_chunks = basic_splitter.split_text(sample_document)

print(f"Created {len(basic_chunks)} chunks:")
for i, chunk in enumerate(basic_chunks, 1):
    print(f"Chunk {i}: {chunk[:100]}...")
    # Check if chunk breaks mid-sentence
    if not chunk.strip().endswith(('.', '!', '?')):
        print("  ‚ö†Ô∏è  Breaks mid-sentence!")
    else:
        print("  ‚úÖ Ends at sentence boundary")
    print()

# Test 2: Sentence-aware chunking (if spaCy available)
if nlp:
    print("üîß Test 2: Sentence-Aware Chunking with spaCy")
    print("-" * 50)
    
    sentence_splitter = SpacyTextSplitter(
        chunk_size=400,
        chunk_overlap=50
    )
    
    sentence_chunks = sentence_splitter.split_text(sample_document)
    
    print(f"Created {len(sentence_chunks)} chunks:")
    for i, chunk in enumerate(sentence_chunks, 1):
        print(f"Chunk {i}: {chunk[:100]}...")
        # Check if chunk breaks mid-sentence
        if not chunk.strip().endswith(('.', '!', '?')):
            print("  ‚ö†Ô∏è  Breaks mid-sentence!")
        else:
            print("  ‚úÖ Ends at sentence boundary")
        print()
    
    print("üîç Comparison:")
    print("Basic chunking:")
    print("  - May break mid-sentence")
    print("  - Can lose semantic meaning")
    print("  - Simpler implementation")
    print()
    print("Sentence-aware chunking:")
    print("  - Preserves sentence boundaries")
    print("  - Better semantic coherence")
    print("  - More natural chunk breaks")
    print("  - Better for NLP processing")
else:
    print("‚ö†Ô∏è  spaCy not available - skipping sentence-aware chunking demo")
    print("üí° Install spaCy with: python -m spacy download en_core_web_sm")

print("üí° Sentence Boundary Benefits:")
print("‚úÖ Preserves complete thoughts and ideas")
print("‚úÖ Better semantic coherence")
print("‚úÖ More natural chunk breaks")
print("‚úÖ Improved readability")
print("‚úÖ Better for language processing")

# Create completion marker
with open("sentence_chunking_complete.txt", "w") as f:
    f.write("Sentence chunking demo completed successfully")

print("\n‚úÖ Sentence chunking demo completed!")
